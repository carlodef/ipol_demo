<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<div id="layout-content">
<h1>Block Matching methods</h1>
<p>The following matching costs are defined for patches centered at the pixel positions <img class="eq" src="eqs/1843971597660114635-130.png" alt="{mathbf p}" style="vertical-align: -4px" /> and <img class="eq" src="eqs/1843971597659114508-130.png" alt="{mathbf q}" style="vertical-align: -4px" />.</p>
<p>The matching costs described below are trivially extended to color images by not making distinctions between the channels. 
This is equivalent to consider larger patches (three times the number of pixels) containing the pixel values from all the channels.</p>
<p><a name="SSD"></a></p>
<p><a name="SAD"></a></p>
<h2>SSD (sum of squared differences) and SAD (sum of absolute differences)</h2>
<p>By taking <img class="eq" src="eqs/4624996489055938393-130.png" alt="p={1,2}" style="vertical-align: -5px" /> in the following equation, we have the <i>Sum of Absolute Differences</i> (SAD) and the <i>Sum of Squared Differences</i> (SSD) respectively:</p>

<div class="eqwl"><img class="eqwl" src="eqs/8981065748085942837-130.png" alt="  mbox{SSD}(mathbf p,mathbf q) := sum_{mathbf t in B(0,r)} | u({mathbf p} + mathbf  t), v({mathbf q} + mathbf  t)|^p. " />
<br /></div><p>But any value of <img class="eq" src="eqs/14336043121-130.png" alt="p" style="vertical-align: -4px" /> will work as well.</p>
<p><a name="SSD-mean"></a></p>
<p><a name="ZSSD"></a></p>
<h2>ZSSD (Zero mean SSD, or SSD-mean)</h2>
<p>The <i>Zero-mean SSD</i>  adds invariance with respect to additive contrast changes to the SSD. It is defined by</p>

<div class="eqwl"><img class="eqwl" src="eqs/4828211295962386213-130.png" alt="    mbox{ZSSD}(mathbf p, mathbf q) :=  sum_{mathbf t in B(0,r)}     left| u({mathbf p} + mathbf  t) -  v({mathbf q} + mathbf t)  +       mu_v({mathbf q})-  mu_u({mathbf p}) right|^2 ,     " />
<br /></div><p>where 
<img class="eq" src="eqs/3917973275485615264-130.png" alt="textstyle  mu_u({mathbf p})= frac{1}{| B(0,r)|} sum_{mathbf t in B(0,r)} u(mathbf p+mathbf t) " style="vertical-align: -11px" />
is the precomputed average of pixel values in <img class="eq" src="eqs/14976045044-130.png" alt="u" style="vertical-align: -1px" /> over the block centered at <img class="eq" src="eqs/6631745838316983663-130.png" alt="mathbf p" style="vertical-align: -4px" />. 
The ZSSD cannot be implemented with integral images if expressed in this form, because the pixel value distances are dependent on the position of the pixels. Indeed,
depending on the position, a different pair of means <img class="eq" src="eqs/8422673725919766916-130.png" alt="mu_{v}" style="vertical-align: -4px" /> and <img class="eq" src="eqs/8422673725918767041-130.png" alt="mu_{u}" style="vertical-align: -4px" /> are being subtracted. However, expanding the square we get   </p>

<div class="eqwl"><img class="eqwl" src="eqs/9003854934541285920-130.png" alt="     mbox{ZSSD}(mathbf p,mathbf q) :=    mbox{SSD}(mathbf p,mathbf q) -       {|B(0,r)|} left(   mu_v({mathbf q})-  mu_u({mathbf p})  right)^2  " />
<br /></div><p>and since <img class="eq" src="eqs/5556496090409757855-130.png" alt=" mu_v(cdot)" style="vertical-align: -5px" /> and  <img class="eq" src="eqs/4177766749675635107-130.png" alt="mu_u(cdot)" style="vertical-align: -5px" /> can be also precomputed by integral images, the overall cost of ZSSD is comparable to  SSD.</p>
<p><a name="SSD/Norm"></a></p>
<p><a name="SSDNorm"></a></p>
<h2>SSD/Norm</h2>
<p>Normalizing the patches by their <img class="eq" src="eqs/6653501418136561567-130.png" alt="L^2" style="vertical-align: -0px" />-norms 
renders the comparison robust to multiplicative contrast changes. The SSD/Norm is defined as</p>

<div class="eqwl"><img class="eqwl" src="eqs/9146174267786106849-130.png" alt="   mbox{SSD/Norm}(mathbf p, mathbf q) :=    sum_{ mathbf t in B(0,r)}     left| frac{ u({mathbf p} + mathbf  t) } { | u|_{B({mathbf p},r)} | }   -     frac{ v({mathbf q} + mathbf t) } { | v|_{B({mathbf q},r)} | }    right|^2 ,     " />
<br /></div><p>where <img class="eq" src="eqs/3389877632690561730-130.png" alt="textstyle | u|_{B({mathbf p},r)} |  =  sqrt{sum_{mathbf t in B(0,r)} left( u(mathbf p+mathbf t) right)^2}" style="vertical-align: -16px" />. Expanding the above expression we get to a correlation formula</p>

<div class="eqwl"><img class="eqwl" src="eqs/2827285073397573980-130.png" alt="     mbox{SSD/Norm}(mathbf p, mathbf q) := 2 -    2     frac{ mbox{Prod}(mathbf p ,mathbf q) } {  | u|_{B({mathbf p},r)} | ,, | v|_{B({mathbf q},r)} | } , " />
<br /></div><p>where <img class="eq" src="eqs/556873935644370321-130.png" alt=" mbox{Prod}(mathbf p ,mathbf q):=  sum_{mathbf t in B(0,r)}  u({mathbf p} + mathbf  t)  v({mathbf q} + mathbf t) " style="vertical-align: -10px" />, which  can be computed using integral images by taking <img class="eq" src="eqs/5456928493784924891-130.png" alt="d(a,b) = ab" style="vertical-align: -5px" />,  and  the terms <img class="eq" src="eqs/8530070382359367265-130.png" alt="  | u|_{B({mathbf p},r)} | " style="vertical-align: -8px" /> and <img class="eq" src="eqs/3648993929893221001-130.png" alt=" | v|_{B({mathbf q},r)} |" style="vertical-align: -8px" /> can be precomputed.</p>
<p>The implementation of this cost should prevent dividing by zero. Under this circumstance, the cost should be set to <img class="eq" src="eqs/6400019251-130.png" alt="2" style="vertical-align: -0px" />. </p>
<p><a name="NCC"></a></p>
<h2>NCC (normalized cross correlation)</h2>
<p>The <i>Normalized Cross Correlation</i>  combines the benefits of ZSSD and SSDNorm as it is invariant to affine contrast changes. It is defined as</p>

<div class="eqwl"><img class="eqwl" src="eqs/2085717167633313050-130.png" alt="    mbox{NCC}(mathbf p, mathbf q) :=  1 - mbox{Corr}(mathbf p, mathbf q) , " />
<br /></div><p>with</p>

<div class="eqwl"><img class="eqwl" src="eqs/7340947347923238866-130.png" alt="   mbox{Corr}(mathbf p, mathbf q) :=     frac{       frac1{|B(0,r)|}  sum_{mathbf t in B(0,r)}       left( u(mathbf p + mathbf  t) -  mu_u{(mathbf p)}right)        left( v(mathbf q + mathbf  t) -  mu_v{(mathbf q)}right)    }{    sqrt{ sigma^2left(  u|_{B({mathbf p},r)} right)   ,  sigma^2left(  v|_{B({mathbf q},r)} right)  }     } ,   " />
<br /></div><p>and where <img class="eq" src="eqs/3521252639807881927-130.png" alt=" sigma^2left( u|_{B({mathbf p},r)}right) " style="vertical-align: -8px" /> is the sample variance of the block centered at <img class="eq" src="eqs/6631745838316983663-130.png" alt="mathbf p" style="vertical-align: -4px" />.</p>
<p><img class="eq" src="eqs/1300343856184772223-130.png" alt="mbox{Corr}" style="vertical-align: -1px" /> takes values in <img class="eq" src="eqs/1255166291386171885-130.png" alt="[-1,1]" style="vertical-align: -5px" />, where 1 indicates the maximum correspondence.  For a consistent notation across the different methods <img class="eq" src="eqs/1863325621398195352-130.png" alt="mbox{NCC}" style="vertical-align: -1px" /> is defined as <img class="eq" src="eqs/3349518600888240919-130.png" alt="1 - mbox{Corr}" style="vertical-align: -1px" />.
The above expression can be written as</p>

<div class="eqwl"><img class="eqwl" src="eqs/4809306182616443819-130.png" alt="    mbox{Corr}(mathbf p, mathbf q) :=    frac{   frac1{|B(0,r)|}  mbox{Prod}(mathbf p,mathbf q) -  mu_u{(mathbf p)}  ,cdot , mu_v{(mathbf q)}     }{     sqrt{ sigma^2left(  u|_{B({mathbf p},r)} right)   ,  sigma^2left(  v|_{B({mathbf q},r)} right)  }   } , " />
<br /></div><p>which can be computed using one integral image (for <img class="eq" src="eqs/3949718267131509954-130.png" alt="mbox{Prod}" style="vertical-align: -1px" />) for each offset value (<img class="eq" src="eqs/7826318392590366519-130.png" alt="mathbf p-mathbf q" style="vertical-align: -4px" />), and where the terms <img class="eq" src="eqs/7083357291911388125-130.png" alt="mu" style="vertical-align: -4px" /> and <img class="eq" src="eqs/1833092850354643519-130.png" alt="sigma^2" style="vertical-align: -1px" /> can be precomputed by integral images too!</p>
<p>The implementation of this cost must prevent dividing by zero. Under that circumstance the cost should be set to <img class="eq" src="eqs/6272018864-130.png" alt="1" style="vertical-align: -0px" />. </p>
<p><a name="AFF"></a></p>
<h2>AFF (&ldquo;affine&rdquo; similarity measure)</h2>
<p>The <i>&ldquo;affine&rdquo; similarity measure</i> proposed by <a href="http://dx.doi.org/10.1137/090766371">Delon and Desolneux (2010)</a> is also invariant to affine contrast changes, but differently from NCC it can distinguish flat patches from those containing edges. It can be seen from the definition of <img class="eq" src="eqs/1300343856184772223-130.png" alt="mbox{Corr}" style="vertical-align: -1px" /> that if one of the patches is flat, then the correlation will be zero independently of the content of the second patch.
In contrast, the <i>&ldquo;affine&rdquo; similarity measure</i> defined below can be non zero under the same circumstances:</p>

<div class="eqwl"><img class="eqwl" src="eqs/2481437876347511874-130.png" alt="    mbox{AFF}(mathbf p, mathbf q) :=  max left( min_{alphage0, beta} left| U_{{mathbf p}} - alpha V_{{mathbf q}}  - beta right| ,                  min_{alphage0, beta} left|  V_{{mathbf q}} - alpha U_{{mathbf p}}  - beta right|  right)   , " />
<br /></div><p>where <img class="eq" src="eqs/1817402030919269691-130.png" alt="U_{{mathbf p}}=u|_{B({mathbf p},r)}" style="vertical-align: -8px" />, <img class="eq" src="eqs/4026789115673513503-130.png" alt="V_{{mathbf q}}=v|_{B({mathbf q},r)}" style="vertical-align: -8px" /> and <img class="eq" src="eqs/7073524312761763077-130.png" alt="| cdot |" style="vertical-align: -5px" /> denotes the <img class="eq" src="eqs/6653501418136561567-130.png" alt="L^2" style="vertical-align: -0px" />-norm. 
It can be explicitly computed by the formula</p>

<div class="eqwl"><img class="eqwl" src="eqs/712087104718767656-130.png" alt="    mbox{AFF}^2(mathbf p, mathbf q) :=  max left( sigma^2left(  u|_{B({mathbf p},r)} right)   ,  sigma^2left(  v|_{B({mathbf q},r)} right)  right)  cdot min left(1, 1- mbox{Corr}( {mathbf p}, {mathbf q} ) |    mbox{Corr}( {mathbf p}, {mathbf q} ) | right), " />
<br /></div><p>which can be implemented with integral images after pre-computing <img class="eq" src="eqs/7126214602153675263-130.png" alt=" sigma^2left(  u|_{B({mathbf p},r)} right) " style="vertical-align: -8px" /> and <img class="eq" src="eqs/3756722856224351637-130.png" alt="  sigma^2left(  v|_{B({mathbf q},r)} right)" style="vertical-align: -8px" />, which in turn can be done with two integral images, one for the square of <img class="eq" src="eqs/14976045044-130.png" alt="u" style="vertical-align: -1px" /> and one for <img class="eq" src="eqs/14976045044-130.png" alt="u" style="vertical-align: -1px" />.</p>
<p><a name="LIN"></a>
<b>LIN</b>  is a simpler variant of the AFF cost that drops the invariance to additive changes, but has a similar performance </p>

<div class="eqwl"><img class="eqwl" src="eqs/5032283924425562166-130.png" alt="    mbox{LIN}(mathbf p, mathbf q) :=  max left( min_{alphage0} left| U_{{mathbf p}} - alpha V_{{mathbf q}}  right| ,                  min_{alphage0} left|  V_{{mathbf q}} - alpha U_{{mathbf p}} right|  right). " />
<br /></div><p>It can also be implemented with integral images by re-writing it as</p>

<div class="eqwl"><img class="eqwl" src="eqs/3405314062519414590-130.png" alt="    mbox{LIN}^2(mathbf p, mathbf q) :=  max(| U_{{mathbf p}}|^2 , | V_{{mathbf q}}|^2)     left( 1- frac{left[   mbox{Prod}( {mathbf p}, {mathbf q} )right]^2}{| U_{{mathbf p}}|^2  | V_{{mathbf q}}|^2} right). " />
<br /></div><p>The implementation of these costs must prevent dividing by zero. Under that circumstance, the cost should be set respectively to the maximum variance or norm of the two patches. </p>
<p><a href="http://dx.doi.org/10.1137/090766371"><i>Delon,J. and Desolneux,A. (2010). Stabilization of Flicker-like effects in image sequences through local contrast correction. SIAM Journal on Imaging Sciences, 3(4):703–734.</i></a></p>
<p><a name="BTSSD"></a></p>
<p><a name="BTSAD"></a></p>
<h2>BTSAD and BTSSD (Birchfield &amp; Tomasi sampling insensitive pixel dissimilarities)</h2>
<p>By BTSAD or BTSSD, we mean an adaptation to SAD or SSD of the <a href="http://dx.doi.org/10.1109/34.677269">Birchfield and Tomasi (1998)</a> sampling insensitive pixel dissimilarity.
This matching cost, originally proposed for stereo matching, is designed to be insensitive to image sampling. For smooth (non aliased) images this cost is proven to be stable with respect to subpixel translations of the patches, while still evaluating the costs at integer positions. </p>
<p>This cost is particularly useful in combination with global block matching methods (Dynamic Programming for instance), where the dissimilarity is accumulated along scanlines, and where the subpixel computations are unaffordable. The insensitivity usually prevents the misclassification of some pixels as occlusions. </p>
<p>The usefulness of this matching cost for a &lsquo;&lsquo;local&rsquo;&rsquo; block matching method is less clear, since the minimum SAD/SSD cost may not change. Nevertheless it is worth comparing its performance with subpixel matching.</p>
<p>The matching costs proposed by Birchfield & Tomasi replace the definition of the pixel value distances with <img class="eq" src="eqs/372427302169781142-130.png" alt="d^{BT}" style="vertical-align: -1px" />. For the case of the SSD we get</p>

<div class="eqwl"><img class="eqwl" src="eqs/2303322505286995900-130.png" alt="  BTSSD(mathbf p,mathbf q) := sum_{mathbf t in B(0,r)} d^{BT}( I_{L}({mathbf p} + mathbf  t), I_{R}({mathbf q} + mathbf  t)), " />
<br /></div><p>where the distance <img class="eq" src="eqs/372427302169781142-130.png" alt="d^{BT}" style="vertical-align: -1px" /> is defined as a symmetrization of the distance by </p>

<div class="eqwl"><img class="eqwl" src="eqs/6725325580158916397-130.png" alt="  d^{BT}(I_{L}(mathbf p) , I_{R}(mathbf q)) =  min ( bar d ( I_{L}(mathbf p), I_{R}(mathbf q)), bar d ( I_{R}(mathbf q), I_{L}(mathbf p)) ),  " />
<br /></div><p>and where <img class="eq" src="eqs/6204835575347082671-130.png" alt="bar d" style="vertical-align: -1px" /> is</p>

<div class="eqwl"><img class="eqwl" src="eqs/6843912558355583096-130.png" alt=" bar d ( I_{L}(mathbf p), I_{R}(mathbf q))= max (0,I_{L}(mathbf p) - I^{max}_{R}(mathbf q),I^{min}_{R}(mathbf q) - I_{L}(mathbf p)), " />
<br /></div>
<div class="eqwl"><img class="eqwl" src="eqs/9126051966661803150-130.png" alt=" bar d ( I_{R}(mathbf q), I_{L}(mathbf p))= max (0,I_{R}(mathbf q) - I^{max}_{L}(mathbf p),I^{min}_{L}(mathbf p) - I_{R}(mathbf q)). " />
<br /></div><p>The four precomputed images <img class="eq" src="eqs/8227995505412914565-130.png" alt="I^{max}_{R}, I^{min}_{R},I^{max}_{L}, I^{min}_{L}" style="vertical-align: -6px" />
contain the maximum and minimum interpolated values of the image in a half pixel neighbor. For instance, with <img class="eq" src="eqs/4424044050822151651-130.png" alt="I_{R}" style="vertical-align: -4px" />  we have</p>

<div class="eqwl"><img class="eqwl" src="eqs/2160267234804887891-130.png" alt=" I^{min}_{R}(mathbf q) = min(I^-_{R}(mathbf q), I^+_{R}(mathbf q),I_{R}(mathbf q)) quad mbox{and} quad  I^{max}_{R}(mathbf q) = max(I^-_{R}(mathbf q), I^+_{R}(mathbf q),I_{R}(mathbf q)), " />
<br /></div><p>where the interpolated values are computed by bilinear interpolation:</p>

<div class="eqwl"><img class="eqwl" src="eqs/3853805172754246656-130.png" alt="  I^-_{R}(mathbf q) = frac12(I_{R}(mathbf q)+I_{R}(mathbf q-(1,0)^T)), quad I^+_{R}(mathbf q)  =frac12(I_{R}(mathbf q)+I_{R}(mathbf q+(1,0)^T)).  " />
<br /></div><p>Note that the maximum (and minimum) of the interpolated pixels <img class="eq" src="eqs/5627703011253386416-130.png" alt="I^{max}" style="vertical-align: -0px" /> (resp. <img class="eq" src="eqs/5627711011231386298-130.png" alt="I^{min}" style="vertical-align: -0px" />) are only computed along the horizontal axis (definitions of <img class="eq" src="eqs/8415076117974416217-130.png" alt="I^+" style="vertical-align: -0px" /> and <img class="eq" src="eqs/8415076117974416223-130.png" alt="I^-" style="vertical-align: -0px" />). This is because the cost was originally proposed for stereo matching, so the subpixel differences are supposed to occur only along the horizontal axis. A straightforward extension of this cost for two dimensional block matching replaces the definition of <img class="eq" src="eqs/5627703011253386416-130.png" alt="I^{max}" style="vertical-align: -0px" /> (resp. <img class="eq" src="eqs/5627711011231386298-130.png" alt="I^{min}" style="vertical-align: -0px" />) to consider subpixel offsets also in the vertical direction</p>

<div class="eqwl"><img class="eqwl" src="eqs/667939860300370698-130.png" alt="  I^{max}(mathbf q) = max  left{ hat I(mathbf q+ mathbf V) right}  quad mbox{with} quad mathbf V = left[-1/2,1/2right]^2, " />
<br /></div><p>where <img class="eq" src="eqs/4030995361092090316-130.png" alt="hat I" style="vertical-align: -0px" /> denotes the bilinear interpolation of the image <img class="eq" src="eqs/9344028104-130.png" alt="I" style="vertical-align: -0px" />. For this interpolation the maximum (resp. minimum) will occur at one of nine possible positions, therefore</p>

<div class="eqwl"><img class="eqwl" src="eqs/3878325074275010234-130.png" alt="  I^{max}(mathbf q) = max  left{ hat I(mathbf q+ mathbf s) : s in {-frac12, 0,frac12} times {-frac12, 0,frac12} right}. " />
<br /></div><p><a href="http://dx.doi.org/10.1109/34.677269"><i>Birchfield,S. and Tomasi,C. (1998). A Pixel Dissimilarity Measure that is Insensitive To Image Sampling, IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(4):401-406.</i></a></p>
<p><a name="SUBPIXEL_BRUTEFORCE"></a></p>
<h2>Subpixel</h2>
<p>This option permits to compute a subpixel disparity map. It is important to note that this is not a subpixel refinement step, the algorithm will consider all the subpixel disparities within the disparity range. This option is ignored when computing 2D displacement fields.</p>
<p><a name="OUTPUT_AND_STATISTICS"></a></p>
<h1>Output, Evaluation and Statistics</h1>
<p>The output of the block matching methods always contain the following images:</p>
<ul>
<li><p><b>disparity</b>: Represents the computed disparity map using a grayscale coding. 
Next to this disparity map, another image is displayed for those stereo pairs that provide a ground truth.
This second image (titled <b>METHOD/error</b> ) shows the differences between the computed disparity and the ground truth.</p>
</li>
<li><p><b>matching cost</b>: Represents the minimum matching cost for each pixel, using a grayscale coding (black is 0).</p>
</li>
<li><p><b>back-projection</b>: Is obtained by warping the secondary image using the displacement field <img class="eq" src="eqs/8083642785274359168-130.png" alt="varepsilon: mathbf Z^2 to mathbf R^2" style="vertical-align: -1px" /> computed from the first image to the second image (denoted <img class="eq" src="eqs/4703415290002371147-130.png" alt="u:mathbf Z^2 to mathbf R" style="vertical-align: -1px" /> and <img class="eq" src="eqs/4461828227276889256-130.png" alt="v:mathbf Z^2 to mathbf R" style="vertical-align: -1px" /> respectively). That is, the backprojection is 
<div class="eqwl"><img class="eqwl" src="eqs/9160990899431494494-130.png" alt=" widetilde v(mathbf x) = v( mathbf x + mathbf varepsilon(mathbf x)). " />
<br /></div> Warping <img class="eq" src="eqs/15104045431-130.png" alt="v" style="vertical-align: -1px" /> using the ground truth displacement field, produces an image that matches (except at the occlusions) the first image. Thus, comparing <img class="eq" src="eqs/5701205108492383413-130.png" alt="widetilde v" style="vertical-align: -1px" /> with <img class="eq" src="eqs/14976045044-130.png" alt="u" style="vertical-align: -1px" /> permits to assess the quality of the displacement field. To facilitate the comparison the image <i>back-projection/error</i> shows the pixel-wise difference <img class="eq" src="eqs/1217057553961778145-130.png" alt="|u(mathbf x) - widetilde v(mathbf x)|" style="vertical-align: -5px" />, shown using a grayscale coding.</p>
</li>
<li><p><b>first/second image</b>: The color range of poorly contrasted images is stretched for visualization.</p>
</li>
</ul>
<p>When the ground truth for the stereo pair is available, the errors with respect to it are computed and shown. 
The errors are shown as images with fixed range from -4 to 4. In this case the following images are also shown as part of the output:</p>
<ul>
<li><p><b>ground truth</b>: Represents the ground truth using a grayscale coding.</p>
</li>
<li><p><b>evaluation mask</b>: Is an optional input image that indicates which pixels are considered (white) in the computation of the statistics (usually the boundaries are not considered). The pixels discarded by the evaluation mask are not shown in the error displays, are not considered in the statistics and are also removed from the non-occluded mask (see below). </p>
</li>
</ul>
<table class="imgtable"><tr><td>
<img src="eval.png" alt="alt text" width="300px" />&nbsp;</td>
<td align="left"><p>Evaluation mask example</p>
</td></tr></table>
<ul>
<li><p><b>occlusion mask</b>: Is a binary mask indicating which pixels are occluded (black), and therefore not considered for the computation of the statistics on Non Occluded areas. This mask is only present in the default input datasets of the demo.</p>
</li>
</ul>
<table class="imgtable"><tr><td>
<img src="occ.png" alt="alt text" width="300px" />&nbsp;</td>
<td align="left"><p>Occlusion mask example</p>
</td></tr></table>
<ul>
<li><p><b>Show |Err| &gt; 1</b>: This binary mask indicates the points where the ground truth and the computed disparity differ more than 1 pixel <img class="eq" src="eqs/8325518086221065861-130.png" alt="|mbox{GT}-varepsilon| &gt; 1" style="vertical-align: -5px" />. These pixels are superimposed on the disparity map and painted in RED.</p>
</li>
</ul>
<h2>Statistics</h2>
<p>The statistics consider two aspects of the results: the density and the precision with respect to the ground truth disparity. 
The errors are computed as the absolute difference between computed disparity values and the ground truth. </p>
<ul>
<li><p><b>Density</b>: It is the percentage of pixels that for which the algorithm has returned a disparity. This quantity does not consider the pixels removed by the evaluation mask.</p>
</li>
<li><p><b>Percentage of pixels with error &gt; 1 in the Evaluation Mask</b>: This quantity is computed considering the pixels in the evaluation mask.</p>
</li>
<li><p><b>Percentage of pixels with error &gt; 1 in Occluded areas</b>: Considers the occluded pixels (according to the mask) that are in the evaluation mask. Since the occluded regions cannot be seen in one of the images, this quantity evaluates how well the algorithm extrapolates the disparity map. </p>
</li>
<li><p><b>Percentage of pixels with error &gt; 1 in NON Occluded areas</b>: Considers the non-occluded pixels that are in the evaluation mask. This quantity is similar to <i>Eval. Mask</i> but is not contaminated by the errors on occluded regions.</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2013-12-30 11:39:32 CET, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
